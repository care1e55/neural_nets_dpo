{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython import display\n",
    "from matplotlib import pyplot as plt\n",
    "% matplotlib inline\n",
    "\n",
    "def visualize(l1,l2, h1, h2):\n",
    "    plt.figure(figsize=(20,5)) \n",
    "    epo_range = range(1,len(h1)+1)\n",
    "    tick_range = range(1,len(h1)+1,2)\n",
    "    plt.subplot(1,2,1)\n",
    "    plt.title('Learning loss')\n",
    "    plt.plot(epo_range,l1, label='train set')\n",
    "    plt.plot(epo_range,l2, label='valid set')\n",
    "    plt.grid()\n",
    "    plt.xticks(tick_range)\n",
    "    plt.legend(title = 'Loss at:')\n",
    "    \n",
    "    plt.subplot(1,2,2)\n",
    "    plt.title('Learning accuracy')\n",
    "    plt.plot(epo_range,h1, label='train set')\n",
    "    plt.plot(epo_range,h2, label='valid set')\n",
    "    plt.grid()\n",
    "    plt.xticks(tick_range)\n",
    "    plt.ylim(0, 1.)\n",
    "    plt.legend(title = 'Accuracy at:')\n",
    "    \n",
    "    display.clear_output(wait=True)\n",
    "    plt.show()\n",
    "    \n",
    "import keras # внутри keras уже есть набор данных, подгрузим его \n",
    "# дубль функции выше, чтобы было удобнее\n",
    "def load_dataset(flatten=False):\n",
    "    (X_train, y_train), (X_test, y_test) = keras.datasets.mnist.load_data()\n",
    "\n",
    "    # нормализация матриц\n",
    "    X_train = X_train.astype(float) / 255.\n",
    "    X_test = X_test.astype(float) / 255.\n",
    "\n",
    "    # последние 10000 примеров из трэйна оставим для валидации\n",
    "    X_train, X_val = X_train[:-10000], X_train[-10000:]\n",
    "    \n",
    "    # сделаем OHE для таргета\n",
    "    y_train = keras.utils.to_categorical(y_train)\n",
    "    y_train, y_val = y_train[:-10000], y_train[-10000:]\n",
    "    y_test = keras.utils.to_categorical(y_test)\n",
    "    \n",
    "    return X_train, y_train, X_val, y_val, X_test, y_test\n",
    "\n",
    "X_train, y_train, X_val, y_val, X_test, y_test = load_dataset()\n",
    "\n",
    "X_train = X_train.reshape(X_train.shape[0],28**2)\n",
    "X_val = X_val.reshape(X_val.shape[0],28**2)\n",
    "X_test = X_test.reshape(X_test.shape[0],28**2)\n",
    "\n",
    "def batches_generator(X, y, batch_size):\n",
    "    n_batches = int(X.shape[0]/batch_size) + 1\n",
    "    for batch_idx in range(n_batches):\n",
    "        indices = (batch_idx*batch_size, min(X.shape[0], (batch_idx+1)*batch_size))\n",
    "        yield X[indices[0]:indices[1]], y[indices[0]:indices[1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm # прогресс бар\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "\n",
    "n_epochs=30\n",
    "batch_size=100\n",
    "\n",
    "\n",
    "X = tf.placeholder(name='input', shape=[None, 784], dtype = tf.float32)\n",
    "# правильные метки классов\n",
    "Y_ = tf.placeholder(tf.float32, [None, 10])\n",
    "\n",
    "\n",
    "\n",
    "# layers sizes\n",
    "L1 = 200\n",
    "L2 = 100\n",
    "L3 = 60\n",
    "L4 = 30\n",
    "L5 = 10\n",
    "\n",
    "# weights - иниацилизируем случайными весами\n",
    "\n",
    "W1 = tf.Variable(tf.truncated_normal([784, L1], stddev=0.1))\n",
    "b1 = tf.Variable(tf.zeros([L1]))\n",
    "\n",
    "W2 = tf.Variable(tf.truncated_normal([L1, L2], stddev=0.1))\n",
    "b2 = tf.Variable(tf.zeros([L2]))\n",
    "\n",
    "W3 = tf.Variable(tf.truncated_normal([L2, L3], stddev=0.1))\n",
    "b3 = tf.Variable(tf.zeros([L3]))\n",
    "\n",
    "W4 = tf.Variable(tf.truncated_normal([L3, L4], stddev=0.1))\n",
    "b4 = tf.Variable(tf.zeros([L4]))\n",
    "\n",
    "W5 = tf.Variable(tf.truncated_normal([L4, L5], stddev=0.1))\n",
    "b5 = tf.Variable(tf.zeros([L5]))\n",
    "\n",
    "gamma=tf.Variable(tf.truncated_normal([L1],0,0.1)) # константы для batch_norm\n",
    "beta=tf.Variable(tf.truncated_normal([L1],0,0.1))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#Определеям саму модель\n",
    "Y1 = tf.nn.relu(tf.matmul(X, W1) + b1)\n",
    "mean, var = tf.nn.moments(Y1, axes=[0])\n",
    "Y1_batch_norm = gamma*((Y1-mean)/tf.sqrt(var+0.001))+beta # вставляем butch_norm\n",
    "\n",
    "Y2 = tf.nn.relu(tf.matmul(Y1_batch_norm, W2) + b2)\n",
    "Y3 = tf.nn.relu(tf.matmul(Y2, W3) + b3)\n",
    "Y4 = tf.nn.relu(tf.matmul(Y3, W4) + b4)\n",
    "Ylogits = tf.matmul(Y4, W5) + b5\n",
    "Y = tf.nn.softmax(Ylogits)\n",
    "\n",
    "# генерируем наш loss\n",
    "cross_entropy = tf.nn.softmax_cross_entropy_with_logits_v2(logits=Ylogits, labels=Y_)\n",
    "cross_entropy = tf.reduce_mean(cross_entropy)\n",
    "\n",
    "                                                          \n",
    "# accuracy of the trained model, between 0 (worst) and 1 (best)\n",
    "correct_prediction = tf.equal(tf.argmax(Y, 1), tf.argmax(Y_, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "\n",
    "# training, \n",
    "learning_rate = 0.003\n",
    "train_step = tf.train.AdamOptimizer(learning_rate).minimize(cross_entropy)\n",
    "\n",
    "s = tf.InteractiveSession()                 # запускаем сессию для вычислений \n",
    "s.run(tf.global_variables_initializer())    # инициализируем переменные \n",
    "\n",
    "# будем писать значения метрик в вектора \n",
    "loss_test, loss_train  = [ ], [ ] \n",
    "acc_test, acc_train = [ ], [ ]\n",
    "\n",
    "saver = tf.train.Saver()\n",
    "\n",
    "\n",
    "\n",
    "for i in tqdm(range(n_epochs)):\n",
    "#     print(i)\n",
    "    # дробим на этой эпохе данные на батчи \n",
    "    num_batches = (X_train.shape[0] / batch_size) + 1\n",
    "    \n",
    "    # сгенерировали батчи \n",
    "    batch_gen = batches_generator(X_train, y_train, batch_size)\n",
    "    \n",
    "    # пошёл цикл по батчам \n",
    "    for X_batch, y_batch in batch_gen:\n",
    "        # итерация градиентного спуска на текущем батче \n",
    "        s.run(train_step, feed_dict={X: X_batch, Y_: y_batch})\n",
    "    \n",
    "#     # посмотрим на качество модели на трэйне и валидации\n",
    "    loss_train.append(s.run(cross_entropy, {X: X_train, Y_: y_train}))\n",
    "    loss_test.append(s.run(cross_entropy, {X: X_val, Y_: y_val}))\n",
    "    \n",
    "    acc_train.append(s.run(accuracy, {X: X_train, Y_: y_train}))\n",
    "    acc_test.append(s.run(accuracy, {X: X_train, Y_: y_train}))\n",
    "    \n",
    "#     # визуализируем\n",
    "    visualize(loss_train, loss_test, acc_train, acc_test) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
