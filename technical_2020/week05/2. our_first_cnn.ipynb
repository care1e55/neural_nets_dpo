{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Наша первая свёрточная нейросеть \n",
    "\n",
    "Пришло время построить нашу первую свёрточную нейросеть. Будем использовать для этого датасет [fashion MNIST.](https://www.cs.toronto.edu/~kriz/cifar.html) Набор данных включает в себя изображения рукописных цифр.  \n",
    "\n",
    "<img src=\"https://pbs.twimg.com/media/DVhOyJ1XkAACKqT.jpg\" style=\"width:70%\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "tf.__version__ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import Sequential\n",
    "keras, L = tf.keras, tf.keras.layers\n",
    "\n",
    "import numpy as np\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Смотрим на данные \n",
    "\n",
    "Скачаеми приготовим данные. Буквально через минуту в наших руках окажутся $60 000$ картинок размера $28 \\times 28$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fashion_mnist = tf.keras.datasets.fashion_mnist\n",
    "\n",
    "(X_train, y_train), (X_test, y_test) = fashion_mnist.load_data()\n",
    "\n",
    "# Отнормировали данные к отрезку [0;1]\n",
    "X_train = X_train/ 255.\n",
    "X_test = X_test/ 255.\n",
    "\n",
    "class_names = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat',\n",
    "               'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Train samples:\", X_train.shape, y_train.shape)\n",
    "print(\"Test samples:\", X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Нарисуем несколько рандомных картинок из тренировочной выборки. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = 8\n",
    "rows = 2\n",
    "fig = plt.figure(figsize=(2 * cols, 2.5 * rows))\n",
    "for i in range(cols):\n",
    "    for j in range(rows):\n",
    "        random_index = np.random.randint(0, len(y_train))\n",
    "        ax = fig.add_subplot(rows, cols, i * rows + j + 1)\n",
    "        ax.grid(False)\n",
    "        ax.set_xticks([])\n",
    "        ax.set_yticks([])\n",
    "        ax.imshow(X_train[random_index, :], cmap = 'gray')\n",
    "        ax.set_xlabel(class_names[y_train[random_index]])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.  Выбираем для нашей нейросети архитектуру\n",
    "\n",
    "Свёрточная нейронная сеть строится из нескольких разных типов слоёв: \n",
    "\n",
    "* [Conv2D](https://keras.io/layers/convolutional/#conv2d) - Конволюция:\n",
    "    - **filters**: число выходных каналов; \n",
    "    - **kernel_size**: размер окна для свёртки;\n",
    "    - **padding**: padding=\"same\" добавляет нулевую каёмку по краям картинки, чтбы после свёртки размеры картинки не изменялись; padding='valid' ничего не добавляет;\n",
    "    - **activation**: \"relu\", \"tanh\", etc.\n",
    "    - **input_shape**: размер входа\n",
    "* [MaxPooling2D](https://keras.io/layers/pooling/#maxpooling2d) - макспулинг\n",
    "* [Flatten](https://keras.io/layers/core/#flatten) - разворачивает картинку в вектор \n",
    "* [Dense](https://keras.io/layers/core/#dense) - полносвязный слой (fully-connected layer)\n",
    "* [Activation](https://keras.io/layers/core/#activation) - функция активации\n",
    "* [LeakyReLU](https://keras.io/layers/advanced-activations/#leakyrelu) - leaky relu активация\n",
    "* [Dropout](https://keras.io/layers/core/#dropout) - дропаут.\n",
    "\n",
    "\n",
    "В модели, которую мы определим ниже, на вход будет идти тензоры размера __(None, 28, 28, 1)__ и __(None, 10)__. На выходе мы будем получать вероятноть того, что объект относится к конкретному классу. Разменость __None__ заготовлена для размерности батча. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 Полносвязная сетка \n",
    "\n",
    "Соберём полносвязную сетку с нашей предыдущей пары/ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.random.set_seed(42)\n",
    "\n",
    "model_1 = Sequential( )\n",
    "\n",
    "model_1.add(L.Flatten(input_shape=(28, 28)))\n",
    "\n",
    "model_1.add(L.Dense(64))\n",
    "model_1.add(L.BatchNormalization()) \n",
    "model_1.add(L.Activation('relu'))\n",
    "\n",
    "model_1.add(L.Dense(32))\n",
    "model_1.add(L.BatchNormalization()) \n",
    "model_1.add(L.Activation('relu'))\n",
    "\n",
    "model_1.add(L.Dense(16))\n",
    "model_1.add(L.BatchNormalization()) \n",
    "model_1.add(L.Activation('relu'))\n",
    "\n",
    "model_1.add(L.Dense(10, activation='softmax'))\n",
    "\n",
    "model_1.compile(\"adam\", \"sparse_categorical_crossentropy\", metrics=[\"sparse_categorical_accuracy\"])\n",
    "\n",
    "hist = model_1.fit(X_train, y_train, validation_split= 0.2,\n",
    "                        batch_size=500, epochs=20, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(hist.history['loss'])\n",
    "plt.plot(hist.history['val_loss'])\n",
    "plt.legend(['Train loss', 'Validation loss'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nLoss, Accuracy = \", model_1.evaluate(X_test, y_test, verbose=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Посмотрите на качество получившейся модели. Вернитесь по коду вверх и раскоментируйте строки, где картинки нормируются к отрезку $[0;1]$. Переобучите сетку. Что произошло с качеством? \n",
    "* Теперь попробуйте использовать в качестве функции активации линейную функцию. Что произошло с качеством модели?  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Можно посмотреть, где именно сетка ошибается. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model_1.predict_classes(X_test)\n",
    "errors =  y_pred != y_test\n",
    "\n",
    "# срежем только наблюдения, где была ошибка вместе с метками\n",
    "X_err = X_test[errors]\n",
    "y_err = y_test[errors]\n",
    "y_pred = y_pred[errors]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = 4\n",
    "rows = 4\n",
    "fig = plt.figure(figsize=(3 * cols - 1, 4 * rows - 1))\n",
    "for i in range(cols):\n",
    "    for j in range(rows):\n",
    "        random_index = np.random.randint(0, len(y_err))\n",
    "        ax = fig.add_subplot(rows, cols, i * rows + j + 1)\n",
    "        ax.grid('off')\n",
    "        ax.axis('off')\n",
    "        ax.imshow(X_err[random_index, : ], cmap='gray')\n",
    "        ax.set_title('real_class: {} \\n  predict class: {}'.format(class_names[y_err[random_index]], \n",
    "                                                                   class_names[y_pred[random_index]]))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 Свёрточная сетка \n",
    "\n",
    "Во-первых, нужно в явном виде указать, что у нас в изображениях один канал. Иначе питон будет ругаться."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train[:,:,:,np.newaxis].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train[:,:,:,np.newaxis]\n",
    "X_test = X_test[:,:,:,np.newaxis]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь давайте соберём свёртоную сеть: \n",
    "\n",
    "* Свёртка с ядром $5 \\times 5$, same padding и $32$ каналами\n",
    "* ReLU\n",
    "* Макспулинг размера $2 \\times 2$\n",
    "* Свёртка с ядром $5 \\times 5$ и $16$ каналами  и same padding\n",
    "* ReLU\n",
    "* Макспулинг размера $2 \\times 2$ с шагом (strides) $2$ по обеим осям \n",
    "* Дальше сделайте `Flatten` и сделайте два полносвязных слоя с ReLU и $120$ и $60$ нейронами"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.random.set_seed(42)\n",
    "\n",
    "\n",
    "# \n",
    "#  Ваша LeNet сетка :) \n",
    "#  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(hist.history['loss'])\n",
    "plt.plot(hist.history['val_loss'])\n",
    "plt.legend(['Train loss', 'Validation loss'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nLoss, Accuracy = \", model_2.evaluate(X_test, y_test, verbose=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Как видите, точность довольно сильно подскочила. Попробуйте поиграться числом параметров и слоёв так, чтобы их стало меньше, а качество сетки стало лучше. Попробуйте обучать нейросетку большее количество эпох. \n",
    "\n",
    "Снова посмотрим на ошибки. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.squeeze(X_test, axis=3).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model_2.predict_classes(X_test)\n",
    "errors =  y_pred != y_test\n",
    "\n",
    "X_err = np.squeeze(X_test[errors], axis=3)\n",
    "y_err = y_test[errors]\n",
    "y_pred = y_pred[errors]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = 4\n",
    "rows = 4\n",
    "fig = plt.figure(figsize=(3 * cols - 1, 4 * rows - 1))\n",
    "for i in range(cols):\n",
    "    for j in range(rows):\n",
    "        random_index = np.random.randint(0, len(y_err))\n",
    "        ax = fig.add_subplot(rows, cols, i * rows + j + 1)\n",
    "        ax.grid('off')\n",
    "        ax.axis('off')\n",
    "        ax.imshow(X_err[random_index, : ], cmap='gray')\n",
    "        ax.set_title('real_class: {} \\n  predict class: {}'.format(class_names[y_err[random_index]], \n",
    "                                                                   class_names[y_pred[random_index]]))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Вот так, кстати говоря, выглядят ошибки аналогичной неронки на MNIST. Кстати говоря, чтобы посмотреть как именно код работает на этом датасете, достаточно просто поменять первые строки с подгрузкой данных в тетрадку. \n",
    "\n",
    "\n",
    "![ ](https://raw.githubusercontent.com/FUlyankin/neural_nets_econ/master/2019/sem_6_pic/MNIST_error.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3  Data augmentation\n",
    "\n",
    "Попробуем обучить ту же модель, но искуственно расширяя набор данных за счёт [случайных искажений.](https://machinelearningmastery.com/image-augmentation-deep-learning-keras/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* `rotation_range`  значение в градусах (0-180), диапазон, в пределах которого произвольно вращаются изображения;\n",
    "* `width_shift` и `height_shift` это диапазоны (в долях от общей ширины или высоты), в пределах которых можно произвольно переводить изображения по вертикали или горизонтали;\n",
    "* `shear_range` диапазон для рандомных сдвигов\n",
    "* `zoom_range` для случайного масштабирования внутри фотографий\n",
    "* `horizontal_flip` для переворачивания половины изображения по горизонтали\n",
    "* `fill_mode` стратегия для заполнения вновь появившихся пикселей"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datagen = ImageDataGenerator(\n",
    "        rotation_range=40,\n",
    "        width_shift_range=0.2,\n",
    "        height_shift_range=0.2,\n",
    "        shear_range=0.2,\n",
    "        zoom_range=0.2,\n",
    "        horizontal_flip=True,\n",
    "        fill_mode='nearest'\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datagen.fit(X_train) # обучили генератор "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Если обучить нейронку с использованием этих настроек, она никогда не увидит одно и то же изображение дважды. Однако входные данные по-прежнему будут довольно сильно связаны между собой. Мы пытаемся исказить уже существующие объекты так, чтобы они всё ещё оставались собой, но нейронка не выучивала детали, присущие конкретным наблюдениям, то есть __не переобучалась.__ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Настраиваем поток данных \n",
    "# Возьмём одну картинку 10 раз и подадим её на вход\n",
    "\n",
    "it = datagen.flow(np.array(10*[X_train[200]]), np.array(10*[y_train[200]]), batch_size=10) # итератор \n",
    "\n",
    "images, categories = it.next()\n",
    "print(\"Number of images returned by iterator:\", len(images))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = 5\n",
    "rows = 2\n",
    "k = 0\n",
    "\n",
    "fig = plt.figure(figsize=(3 * cols - 1, 4 * rows - 1))\n",
    "for i in range(cols):\n",
    "    for j in range(rows):\n",
    "        im = np.squeeze(images[k], axis=2)\n",
    "        k += 1\n",
    "        \n",
    "        ax = fig.add_subplot(rows, cols, i * rows + j + 1)\n",
    "        ax.grid('off')\n",
    "        ax.axis('off')\n",
    "        ax.imshow(im, cmap='gray')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Настроим поток для всей выборки. Каждая картинка будет искажаться один раз и подаваться на вход в нейронку. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Кусочек откусываем для валидации\n",
    "X_tr, X_val, y_tr, y_val = train_test_split(X_train, y_train, test_size=0.2)\n",
    "\n",
    "it = datagen.flow(X_tr, y_tr, batch_size=256)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Скопируем сетку из предыдущего пункта. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ваша сетка"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обучим сетку. Для этого будем использовать метод `fit_generator`. Так как данные генерируются до бесконечности, модель должна знать сколько образцов надо извлечь перед тем как закончить эпоху. За это отвечает параметр `steps_per_epoch`. После извлечения из генератора `steps_per_epoch` батчей сетка переходит к новой эпохе."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist = model_3.fit_generator(\n",
    "    it,\n",
    "    steps_per_epoch=100,\n",
    "    epochs=20,\n",
    "    validation_data=(X_val, y_val),\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(hist.history['loss'])\n",
    "plt.plot(hist.history['val_loss'])\n",
    "plt.legend(['Train loss', 'Validation loss'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Loss, Accuracy = \", model_4.evaluate(X_test, y_test, verbose=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Такую сетку надо учить подольше. В этой тетрадке она реализована просто как пример аугментации данных. Побиться за реальное улучшение качества вам надо будет в большой домашке по картинкам. Там будут коты и собаки (неожиданно...) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
