{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Стреляем себе в ногу\n",
    " \n",
    "* Давайте разберём на Keras несколько архитектур. Попытайтесь понять что именно с ними не так. \n",
    "* Упражнения позаимствованы [из нескольких ШАДОвских семинаров по Keras.](https://github.com/yandexdataschool/Practical_DL/blob/master/week03_convnets/other_frameworks/how_to_shoot_yourself_in_the_foot_with_cnn.ipynb)\n",
    "\n",
    "#### a) Задача регрессии. Предсказываем цены на недвижимость."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "model = keras.models.Sequential()\n",
    "model.add(L.InputLayer([39]))\n",
    "model.add(L.BatchNormalization())\n",
    "model.add(L.Dense(128, kernel_initializer=keras.initializers.zeros()))\n",
    "model.add(L.Dense(128, kernel_initializer=keras.initializers.zeros()))\n",
    "model.add(L.Dense(1))\n",
    "\n",
    "model.compile(optimizer='sgd', loss='mean_squared_error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential()\n",
    "model.add(L.InputLayer([39]))\n",
    "\n",
    "# лучше нормализовать входы (не ошибка)\n",
    "model.add(L.BatchNormalization())                         \n",
    "\n",
    "# полносвязный слой без нелинейности (нейросеть не лучше линейной регрессии)\n",
    "model.add(L.Dense(128, kernel_initializer=keras.initializers.zeros()))\n",
    "\n",
    "# так ещё и инициализируется нулями (эффект симметрии, нейроны будут одинаковыми)\n",
    "model.add(L.Dense(128, kernel_initializer=keras.initializers.zeros()))\n",
    "model.add(L.Dense(1))\n",
    "\n",
    "# попробовать relative mse, log-mse (не ошибка)\n",
    "model.compile(optimizer='sgd', loss='mean_squared_error') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  б) Классификация картинок, например, fashion MNIST"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "model = keras.models.Sequential()\n",
    "model.add(L.InputLayer([28, 28, 1]))\n",
    "model.add(L.Conv2D(filters=512, kernel_size=(3, 3)))\n",
    "model.add(L.Activation('relu'))\n",
    "model.add(L.MaxPool2D(pool_size=(2, 2)))\n",
    "model.add(L.Flatten())\n",
    "model.add(L.Dense(100))\n",
    "model.add(L.Activation('softmax'))\n",
    "model.add(L.Dropout(0.1))\n",
    "model.add(L.Dense(10))\n",
    "model.add(L.Activation('softmax'))\n",
    "model.add(L.Dropout(0.1))\n",
    "\n",
    "model.compile(optimizer='rmsprop', loss='mean_squared_error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential()\n",
    "model.add(L.InputLayer([28, 28, 1]))\n",
    "\n",
    "# многовато фильтров, вряд ли найдётся 512 значимо разных 3x3 карты\n",
    "model.add(L.Conv2D(filters=512, kernel_size=(3, 3)))\n",
    "model.add(L.Activation('relu'))\n",
    "\n",
    "# relu и max pool можно переставить местами, будет то же самое чуть быстрее (не ошибка)\n",
    "model.add(L.MaxPool2D(pool_size=(2, 2)))\n",
    "model.add(L.Flatten())\n",
    "model.add(L.Dense(100))\n",
    "\n",
    "# softmax плохо подходит для промежуточной нелинейности (почти все нейроны будут близки к 0)\n",
    "model.add(L.Activation('softmax'))\n",
    "\n",
    "model.add(L.Dropout(0.1)) # хороший, годный дропаут\n",
    "model.add(L.Dense(10))\n",
    "model.add(L.Activation('softmax'))\n",
    "\n",
    "# не стоит dropout-ить вероятности на выходе, рискуете получить бесконечный лосс\n",
    "model.add(L.Dropout(0.1))\n",
    "\n",
    "# обучать классификацию по квадратичной ошибке можно, но... это безбожно\n",
    "model.compile(optimizer='rmsprop', loss='mean_squared_error')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### в) И снова fashion MNIST, но теперь мы знаем, что размер картинки $100 \\times 100$ пикселей\n",
    "\n",
    "Если попробовать скомпилировать эту сетку, вылезет ошибка."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "model = keras.models.Sequential()\n",
    "model.add(L.InputLayer([100, 100, 3]))\n",
    "\n",
    "for filters in [32, 64, 128, 256]:\n",
    "    model.add(L.Conv2D(filters, kernel_size=(5, 5)))\n",
    "    model.add(L.Conv2D(filters, kernel_size=(1, 1)))\n",
    "    model.add(L.MaxPooling2D(pool_size=(3, 3)))\n",
    "    model.add(L.Activation('relu'))\n",
    "    model.add(L.BatchNormalization())\n",
    "\n",
    "model.add(L.Flatten())\n",
    "\n",
    "model.add(L.Dense(100, activation='relu'))\n",
    "model.add(L.Dropout(0.5))\n",
    "model.add(L.Dense(10, activation='softmax'))\n",
    "\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential()\n",
    "model.add(L.InputLayer([100, 100, 3]))\n",
    "\n",
    "for filters in [32, 64, 128, 256]:\n",
    "    # на четвёртой итерации вход станет меньше 5x5, свёртка \"не влезет\"\n",
    "    model.add(L.Conv2D(filters, kernel_size=(5, 5)))\n",
    "    model.add(L.Conv2D(filters, kernel_size=(1, 1)))\n",
    "    \n",
    "    # свёртка 1x1 имела бы смысл, если бы перед ней была нелинейность\n",
    "    model.add(L.MaxPooling2D(pool_size=(3, 3)))\n",
    "    model.add(L.Activation('relu'))\n",
    "    model.add(L.BatchNormalization())\n",
    "    # не ошибка, но рекоммендуют вставлять BatchNorm перед активацией (в интернетах много срачей на эту тему)\n",
    "\n",
    "model.add(L.Flatten())\n",
    "\n",
    "model.add(L.Dense(100, activation='relu'))\n",
    "model.add(L.Dropout(0.5))\n",
    "model.add(L.Dense(10, activation='softmax'))\n",
    "\n",
    "# accuracy имеет нулевую производную, поэтому оптимизировать лучше кроссэнтропию\n",
    "# (sparse_categorical_crossentropy)\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_accuracy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
