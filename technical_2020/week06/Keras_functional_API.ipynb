{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Функциональный API\n",
    "\n",
    "Мы хотим строить сложные разветвлённые модели, а не какие-то там жалкие линейные. Ещё хотим трюки разные использовать. Например, делать ResNet слои. В таких ситуациях нам на помощь приходит функциональный API от keras. Он позволяет придумывать и реализовывать сетки как угодно."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Введение в функциональный API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow.keras as  keras\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import Input, layers \n",
    "\n",
    "input_tensor = Input(shape=(32,))\n",
    "dense = layers.Dense(32, activation='relu')\n",
    "output_tensor = dense(input_tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Начнем с маленького примера, который описывает как обычную модель можно представить с помощью функционального API. На самом деле мы с вами уже видели его раньше. Зададим небольшую сетку с помощью класса `Sequential`. Она линейная. Каждый выход это вход для следующего. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential, Model \n",
    "\n",
    "seq_model = Sequential()\n",
    "seq_model.add(layers.Dense(32, activation='relu', input_shape=(64,))) \n",
    "seq_model.add(layers.Dense(32, activation='relu'))\n",
    "seq_model.add(layers.Dense(10, activation='softmax'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "А теперь возьмём её и перепишем в функциональном стиле. Каждый слой это функция, которую мы применяем к какому-то входу. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         [(None, 64)]              0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 32)                1056      \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 10)                330       \n",
      "=================================================================\n",
      "Total params: 3,466\n",
      "Trainable params: 3,466\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "input_tensor = Input(shape=(64,))\n",
    "\n",
    "x = layers.Dense(32, activation='relu')(input_tensor)\n",
    "x = layers.Dense(32, activation='relu')(x)\n",
    "output_tensor = layers.Dense(10, activation='softmax')(x)\n",
    "\n",
    "model = Model(input_tensor, output_tensor)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed to import pydot. You must install pydot and graphviz for `pydotprint` to work.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.utils import plot_model\n",
    "plot_model(model, show_shapes = True)\n",
    "\n",
    "# можно нарисовать картинку \n",
    "# SVG(model_to_dot(model,show_shapes=True).create(prog='dot', format='svg'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Единственная часть, которая может показаться немного волшебной - создание экземпляра объекта `Model` с использованием только входного и выходного тензоров. За кулисами Keras извлекает все слои, участвующие в переходе от `input_tensor` к `output_tensor`, объединяя их в граф вычислений. Тут важно заметить, что `output_tensor` и `input_tensor` связаны межу собой вычислениями. Если попытаться построить модель из входных и выходных данных, которые не были связаны выскочит ошибка. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "unrelated_input = Input(shape=(32,))\n",
    "bad_model = Model(unrelated_input, output_tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ошибка говорит нам о том, что керас не смог достичь `output`, преобразовывая `input`. Всё остальное работает точно также, как и раньше."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1000 samples\n",
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 1s 617us/sample - loss: 12.4903\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 0s 31us/sample - loss: 14.9156\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 0s 27us/sample - loss: 18.3140\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 0s 54us/sample - loss: 21.7487\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 0s 26us/sample - loss: 25.5756\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 0s 14us/sample - loss: 29.6827\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 0s 36us/sample - loss: 33.7241\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 0s 12us/sample - loss: 38.3102\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 0s 44us/sample - loss: 41.8775\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 0s 36us/sample - loss: 46.1290\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "48.51844696044922"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(optimizer='rmsprop', loss='categorical_crossentropy')\n",
    "\n",
    "import numpy as np\n",
    "x_train = np.random.random((1000, 64))\n",
    "y_train = np.random.random((1000, 10)) \n",
    "\n",
    "model.fit(x_train, y_train, epochs=10, batch_size=128)\n",
    "\n",
    "score = model.evaluate(x_train, y_train, verbose=0)\n",
    "score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## 2. Модели с несколькими входами\n",
    "\n",
    "Функциональный API может использоваться для построения моделей с несколькими входами. Как правило, такие модели в какой-то момент объединяют свои ветви, используя слой, который может объединять несколько тензоров. (`keras.layers.add`, `keras.layers.concatenate` и тп)\n",
    "\n",
    "### Диалоговая система\n",
    "\n",
    "Представим себе, что мы пытаемся построить сетку, которая умеет отвечать на вопросы. Чтобы выйчить её, надо показать ей кучу примеров вопросов и ответов на них. У сетки будет два входа. На выходе мы будем получать вероятность того, что ответ релевантен вопросу. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import Input\n",
    "\n",
    "text_vocabulary_size = 10000\n",
    "question_vocabulary_size = 10000\n",
    "answer_vocabulary_size = 500\n",
    "\n",
    "# Ввод текста представляет собой последовательность целых чисел переменной длины.\n",
    "# Обратите внимание, что вы можете по желанию назвать входы\n",
    "text_input = Input(shape=(None,), dtype='int32', name='text')\n",
    "embedded_text = layers.Embedding(text_vocabulary_size,64)(text_input)\n",
    "\n",
    "# С помощью LSTM переводим текст в последовательность\n",
    "encoded_text = layers.LSTM(32)(embedded_text)\n",
    "\n",
    "# Тот же процесс (с разными экземплярами слоя) для вопроса\n",
    "question_input = Input(shape=(None,),dtype='int32',name='question')\n",
    "embedded_question = layers.Embedding(question_vocabulary_size,32)(question_input)\n",
    "encoded_question = layers.LSTM(16)(embedded_question) \n",
    "\n",
    "# Соеденяем вопрос и текст\n",
    "concatenated = layers.concatenate([encoded_text, encoded_question],\n",
    "                                  axis=-1)\n",
    "# Добавляем softmax итоговый\n",
    "answer = layers.Dense(answer_vocabulary_size, activation='softmax')(concatenated)\n",
    "\n",
    "# Модельс 2-мя входами и 1 выходом, поэтому задаем таким образом\n",
    "model = Model([text_input, question_input], answer)\n",
    "model.compile(optimizer='rmsprop',loss='categorical_crossentropy', metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "text (InputLayer)               [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "question (InputLayer)           [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding (Embedding)           (None, None, 64)     640000      text[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "embedding_1 (Embedding)         (None, None, 32)     320000      question[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lstm (LSTM)                     (None, 32)           12416       embedding[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lstm_1 (LSTM)                   (None, 16)           3136        embedding_1[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 48)           0           lstm[0][0]                       \n",
      "                                                                 lstm_1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dense_7 (Dense)                 (None, 500)          24500       concatenate[0][0]                \n",
      "==================================================================================================\n",
      "Total params: 1,000,052\n",
      "Trainable params: 1,000,052\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed to import pydot. You must install pydot and graphviz for `pydotprint` to work.\n"
     ]
    }
   ],
   "source": [
    "plot_model(model, show_shapes = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Обучение модели с несколькими входами"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[8054,  360, 4332, ..., 6235, 5528, 5878],\n",
       "       [6102, 8217, 5513, ..., 6377, 6579, 6850],\n",
       "       [3864, 6967, 4492, ..., 8542, 2155,  145],\n",
       "       ...,\n",
       "       [7360, 5886, 4331, ..., 8644, 1445, 6148],\n",
       "       [6349, 7374, 6710, ..., 6095, 5026,  527],\n",
       "       [9805, 8936, 8299, ..., 8923, 7435, 8762]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "num_samples = 1000 \n",
    "max_length = 100\n",
    "\n",
    "# модельные данные\n",
    "text = np.random.randint(1, text_vocabulary_size,size=(num_samples, max_length))\n",
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 275, 3200, 9866, ..., 2845, 9866, 3427],\n",
       "       [7107, 8775, 5426, ..., 1259,  635, 9621],\n",
       "       [6509, 4273, 4708, ..., 8719, 4789, 4020],\n",
       "       ...,\n",
       "       [8821, 8929, 1657, ..., 2399, 8735, 4123],\n",
       "       [7580, 5237, 7327, ..., 2264, 4803, 1518],\n",
       "       [6172, 5188, 8463, ..., 7259,  649, 7707]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question = np.random.randint(1, question_vocabulary_size,size=(num_samples, max_length))\n",
    "question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# выход из сетки это релевантность ответа вопросу\n",
    "answers = np.random.randint(answer_vocabulary_size, size=(num_samples))\n",
    "answers = keras.utils.to_categorical(answers, answer_vocabulary_size)\n",
    "answers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Подать данные на вход можно двумя способами. Либо как лист:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1000 samples\n",
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 4s 4ms/sample - loss: 6.2148 - acc: 0.0020\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 1s 609us/sample - loss: 6.1977 - acc: 0.0390\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 1s 724us/sample - loss: 6.1456 - acc: 0.0070\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 1s 754us/sample - loss: 6.0684 - acc: 0.0090\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 1s 698us/sample - loss: 5.9958 - acc: 0.0080\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 1s 706us/sample - loss: 5.8934 - acc: 0.0140\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 1s 844us/sample - loss: 5.7897 - acc: 0.0110\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 1s 890us/sample - loss: 5.7059 - acc: 0.0120\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 1s 762us/sample - loss: 5.6233 - acc: 0.0150\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 1s 865us/sample - loss: 5.5542 - acc: 0.0160\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f0d0246dcd0>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit([text, question], answers, epochs=10, batch_size=128)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Либо как словарь:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1000 samples\n",
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 1s 926us/sample - loss: 5.4933 - acc: 0.0190\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 1s 890us/sample - loss: 5.4302 - acc: 0.0210\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 1s 758us/sample - loss: 5.3679 - acc: 0.0270\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 1s 665us/sample - loss: 5.3056 - acc: 0.0320\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 1s 650us/sample - loss: 5.2587 - acc: 0.0310\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 1s 649us/sample - loss: 5.2099 - acc: 0.0420\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 1s 638us/sample - loss: 5.1416 - acc: 0.0460\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 1s 665us/sample - loss: 5.1055 - acc: 0.0450\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 1s 656us/sample - loss: 5.0547 - acc: 0.0410\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 1s 661us/sample - loss: 4.9963 - acc: 0.0470\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f0ce8b7f8d0>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit({'text': text, 'question': question}, answers,epochs=10, batch_size=128)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Модели с несколькими выходами\n",
    "\n",
    "Можно собирать модели с несколькими выходами! \n",
    "\n",
    "### Пример - прогноз возраста, пола и дохода от постов в социальных сетях\n",
    "\n",
    "Сеть пытается предсказать по сообщению человека в социальных сетках его возраст, пол и доход. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocabulary_size = 50000 \n",
    "num_income_groups = 10 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1455,  7155, 48861, ..., 44334, 16038, 12194],\n",
       "       [ 2261,  4525, 45128, ...,  9752, 33206,  1588],\n",
       "       [22284, 35175, 20730, ..., 17430, 11918, 24401],\n",
       "       ...,\n",
       "       [42345, 24480,  7447, ..., 33867, 31447, 39097],\n",
       "       [27833, 44998, 29995, ..., 40870, 20602, 34144],\n",
       "       [37888, 43211,   424, ...,   537, 24239, 30451]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np \n",
    "\n",
    "num_samples = 1000 \n",
    "max_length = 100\n",
    "\n",
    "posts = np.random.randint(1, vocabulary_size, size=(num_samples, max_length))\n",
    "posts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[39],\n",
       "       [58],\n",
       "       [23],\n",
       "       [81],\n",
       "       [70],\n",
       "       [14],\n",
       "       [ 9],\n",
       "       [66],\n",
       "       [36],\n",
       "       [60]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "age_targets = np.random.randint(0, 100, size=(num_samples,1))\n",
    "age_targets[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 1., 0.],\n",
       "       [0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 1., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 1., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
       "       [0., 0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 1., 0., 0., 0., 0., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "income_targets = np.random.randint(1, num_income_groups, size=(num_samples,1))\n",
    "income_targets = keras.utils.to_categorical(income_targets,num_income_groups)\n",
    "income_targets[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gender_targets = np.random.randint(0, 2, size=(num_samples,1))\n",
    "gender_targets[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Собираем модель."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "posts_input = Input(shape=(None,), dtype='int32', name='posts')\n",
    "embedded_posts = layers.Embedding(vocabulary_size,256)(posts_input)\n",
    "\n",
    "x = layers.Conv1D(128, 5, activation='relu', padding='same')(embedded_posts)\n",
    "x = layers.MaxPooling1D(5)(x)\n",
    "x = layers.Conv1D(256, 5, activation='relu', padding='same')(x)\n",
    "x = layers.Conv1D(256, 5, activation='relu', padding='same')(x)\n",
    "x = layers.MaxPooling1D(5)(x)\n",
    "x = layers.Conv1D(256, 5, activation='relu', padding='same')(x)\n",
    "x = layers.Conv1D(256, 5, activation='relu', padding='same')(x) \n",
    "x = layers.GlobalMaxPooling1D()(x)\n",
    "x = layers.Dense(128, activation='relu')(x) \n",
    "\n",
    "# Заметим, что выходным лаерам лучше дать имя.\n",
    "age_prediction = layers.Dense(1, name='age')(x)\n",
    "income_prediction = layers.Dense(num_income_groups,\n",
    "                                 activation='softmax',name='income')(x)\n",
    "\n",
    "gender_prediction = layers.Dense(1, activation='sigmoid',\n",
    "                                 name='gender')(x)\n",
    "\n",
    "model = Model(posts_input,[age_prediction, income_prediction, \n",
    "                           gender_prediction])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Лоя разных выходов надо задавать разные функции потерь. Например, прогнозирование возраста регрессия, пола классификация. Все эти потери надо будет объединить в один функционал. Каждой придать свой вес. Сложно, короче говоря. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# снова либо списком либо словарем, словарь работает если мы дали тензорам имена\n",
    "model.compile(optimizer='rmsprop', loss=['mse', \n",
    "                                         'categorical_crossentropy',\n",
    "                                         'binary_crossentropy'])\n",
    "\n",
    "model.compile(optimizer='rmsprop',loss={'age': 'mse',\n",
    "                                        'income': 'categorical_crossentropy',\n",
    "                                        'gender': 'binary_crossentropy'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посмотрим как можно на разные функции потерь накидывать веса. Из-за того, что они могут быть несбалансированны, один выход может задоминировать другой. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='rmsprop',\n",
    "              loss=['mse', 'categorical_crossentropy', 'binary_crossentropy'],\n",
    "              loss_weights=[0.25, 1., 10.]) \n",
    "\n",
    "model.compile(optimizer='rmsprop',\n",
    "              \n",
    "              loss={'age': 'mse',\n",
    "                    'income': 'categorical_crossentropy',\n",
    "                    'gender': 'binary_crossentropy'},\n",
    "              \n",
    "              loss_weights={'age': 0.25,\n",
    "                            'income': 1.,\n",
    "                            'gender': 10.})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "posts (InputLayer)              [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_2 (Embedding)         (None, None, 256)    12800000    posts[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv1d (Conv1D)                 (None, None, 128)    163968      embedding_2[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d (MaxPooling1D)    (None, None, 128)    0           conv1d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_1 (Conv1D)               (None, None, 256)    164096      max_pooling1d[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_2 (Conv1D)               (None, None, 256)    327936      conv1d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_1 (MaxPooling1D)  (None, None, 256)    0           conv1d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_3 (Conv1D)               (None, None, 256)    327936      max_pooling1d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_4 (Conv1D)               (None, None, 256)    327936      conv1d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d (GlobalMax (None, 256)          0           conv1d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_8 (Dense)                 (None, 128)          32896       global_max_pooling1d[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "age (Dense)                     (None, 1)            129         dense_8[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "income (Dense)                  (None, 10)           1290        dense_8[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "gender (Dense)                  (None, 1)            129         dense_8[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 14,146,316\n",
      "Trainable params: 14,146,316\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed to import pydot. You must install pydot and graphviz for `pydotprint` to work.\n"
     ]
    }
   ],
   "source": [
    "plot_model(model, show_shapes = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Подавать данные на вход снова можно двумя способами."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1000 samples\n",
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 3s 3ms/sample - loss: 660.0024 - age_loss: 2471.4485 - income_loss: 4.6153 - gender_loss: 2.6309\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 2s 2ms/sample - loss: 155.6189 - age_loss: 572.9353 - income_loss: 2.8619 - gender_loss: 0.9811\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 2s 2ms/sample - loss: 83.9520 - age_loss: 276.7404 - income_loss: 2.3599 - gender_loss: 1.1944\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 2s 2ms/sample - loss: 114.6498 - age_loss: 398.0174 - income_loss: 2.3626 - gender_loss: 1.1643\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 2s 2ms/sample - loss: 98.4076 - age_loss: 332.9329 - income_loss: 2.3560 - gender_loss: 1.1483\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 1s 1ms/sample - loss: 113.3189 - age_loss: 421.8441 - income_loss: 2.3374 - gender_loss: 0.9052\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 1s 1ms/sample - loss: 99.3849 - age_loss: 363.9637 - income_loss: 2.2988 - gender_loss: 1.1757\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 1s 1ms/sample - loss: 82.7584 - age_loss: 278.7458 - income_loss: 2.3473 - gender_loss: 0.9749\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 1s 1ms/sample - loss: 77.3139 - age_loss: 256.3089 - income_loss: 2.3101 - gender_loss: 0.9816\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 1s 1ms/sample - loss: 86.0635 - age_loss: 297.9567 - income_loss: 2.3637 - gender_loss: 0.9896\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f0ce80fa750>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(posts, [age_targets, income_targets, gender_targets], epochs=10, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1000 samples\n",
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 2s 2ms/sample - loss: 57.2643 - age_loss: 181.5103 - income_loss: 2.3440 - gender_loss: 0.9099\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 1s 1ms/sample - loss: 78.5701 - age_loss: 269.6850 - income_loss: 2.3117 - gender_loss: 0.8405\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 2s 2ms/sample - loss: 80.1113 - age_loss: 261.4580 - income_loss: 2.3645 - gender_loss: 1.1071\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 2s 2ms/sample - loss: 62.6108 - age_loss: 194.2973 - income_loss: 2.3400 - gender_loss: 1.1605\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 2s 2ms/sample - loss: 66.7655 - age_loss: 218.3465 - income_loss: 2.3678 - gender_loss: 1.0616\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 2s 2ms/sample - loss: 77.5890 - age_loss: 269.5192 - income_loss: 2.3662 - gender_loss: 0.9126 1s - loss: 120.4092 - age_loss: 426.7166 - income_loss: 2.3031 - gend\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 2s 2ms/sample - loss: 51.3145 - age_loss: 152.6366 - income_loss: 2.3750 - gender_loss: 1.0597\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 2s 2ms/sample - loss: 57.6151 - age_loss: 182.3138 - income_loss: 2.3611 - gender_loss: 0.8890\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 2s 2ms/sample - loss: 54.7919 - age_loss: 173.2451 - income_loss: 2.3251 - gender_loss: 0.9074\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 2s 2ms/sample - loss: 60.1486 - age_loss: 198.4214 - income_loss: 2.3807 - gender_loss: 0.7806\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f0cb30697d0>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(posts, {'age': age_targets,\n",
    "                  'income': income_targets,\n",
    "                  'gender': gender_targets},\n",
    "         epochs=10, \n",
    "         batch_size=64)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## 4 Направленные ациклические графы\n",
    "\n",
    "Можно собирать сетки со сложной внутренней топологией. Keras разрешает ориентровать слои как угодно. Главноe, чтобы не было циклов. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### 4.1 Inception модули\n",
    "\n",
    "Ну чтож ваша очередь объяснять, что тут в коде происходит :) не только же мне мучаться:)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x.shape: (None, 28, 28, 1)\n"
     ]
    }
   ],
   "source": [
    "# Пример реализован для MNIST \n",
    "\n",
    "x = Input(shape=(28, 28, 1), dtype='float32', name='images')\n",
    "\n",
    "print(\"x.shape:\",x.shape)\n",
    "\n",
    "\n",
    "branch_a = layers.Conv2D(128, 1, padding='same',\n",
    "                         activation='relu', strides=2)(x)\n",
    "\n",
    "\n",
    "branch_b = layers.Conv2D(128, 1, padding='same', \n",
    "                         activation='relu')(x)\n",
    "branch_b = layers.Conv2D(128, 3, padding='same',\n",
    "                         activation='relu', strides=2)(branch_b)\n",
    "\n",
    "\n",
    "branch_c = layers.AveragePooling2D(3,  padding='same', strides=2)(x)\n",
    "branch_c = layers.Conv2D(128, 3, \n",
    "                         padding='same',\n",
    "                         activation='relu')(branch_c)\n",
    "\n",
    "branch_d = layers.Conv2D(128, 1, padding='same', activation='relu')(x) \n",
    "branch_d = layers.Conv2D(128, 3, padding='same', activation='relu')(branch_d)\n",
    "branch_d = layers.Conv2D(128, 3, padding='same', activation='relu', strides=2)(branch_d)\n",
    "\n",
    "\n",
    "output = layers.concatenate([branch_a, branch_b, branch_c, branch_d], \n",
    "                            axis=-1)\n",
    "\n",
    "output = layers.Flatten()(output)\n",
    "output = layers.Dense(512, activation='relu')(output)\n",
    "predictions = layers.Dense(10, activation='softmax')(output)\n",
    "\n",
    "model_intersept = keras.models.Model(inputs=x, outputs=predictions)\n",
    "model.compile(optimizer=keras.optimizers.RMSprop(lr=2e-3, decay=1e-5),\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "posts (InputLayer)              [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_2 (Embedding)         (None, None, 256)    12800000    posts[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv1d (Conv1D)                 (None, None, 128)    163968      embedding_2[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d (MaxPooling1D)    (None, None, 128)    0           conv1d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_1 (Conv1D)               (None, None, 256)    164096      max_pooling1d[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_2 (Conv1D)               (None, None, 256)    327936      conv1d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_1 (MaxPooling1D)  (None, None, 256)    0           conv1d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_3 (Conv1D)               (None, None, 256)    327936      max_pooling1d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_4 (Conv1D)               (None, None, 256)    327936      conv1d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d (GlobalMax (None, 256)          0           conv1d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_8 (Dense)                 (None, 128)          32896       global_max_pooling1d[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "age (Dense)                     (None, 1)            129         dense_8[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "income (Dense)                  (None, 10)           1290        dense_8[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "gender (Dense)                  (None, 1)            129         dense_8[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 14,146,316\n",
      "Trainable params: 14,146,316\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed to import pydot. You must install pydot and graphviz for `pydotprint` to work.\n"
     ]
    }
   ],
   "source": [
    "plot_model(model, show_shapes = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2  ResNET\n",
    "\n",
    "Теперь очередь Resnet-модуля :) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x.shape: (None, 28, 28, 1)\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras import layers \n",
    "from tensorflow.keras.layers import Input\n",
    "\n",
    "\n",
    "# Этот пример ожидаем 4д тензор\n",
    "# Возвращаем тензор, который ожидаем для MNIST\n",
    "x = Input(shape=(28, 28, 1), dtype='float32', name='images')\n",
    "print(\"x.shape:\",x.shape)\n",
    "\n",
    "# Применяем преобразования\n",
    "y = layers.Conv2D(128, 3, activation='relu', padding='same')(x)\n",
    "y = layers.Conv2D(128, 3, activation='relu', padding='same')(y)\n",
    "y = layers.Conv2D(128, 3, activation='relu', padding='same')(y)\n",
    "\n",
    "# Добавляем х вконец\n",
    "output = layers.add([y, x])\n",
    "\n",
    "# Добавляем сверху классификатор\n",
    "output = layers.Flatten()(output)\n",
    "output = layers.Dense(512, activation='relu')(output)\n",
    "predictions = layers.Dense(10, activation='softmax')(output)\n",
    "model = keras.models.Model(inputs=x, outputs=predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_7\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "images (InputLayer)             [(None, 28, 28, 1)]  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_7 (Conv2D)               (None, 28, 28, 128)  1280        images[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_8 (Conv2D)               (None, 28, 28, 128)  147584      conv2d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_9 (Conv2D)               (None, 28, 28, 128)  147584      conv2d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add (Add)                       (None, 28, 28, 128)  0           conv2d_9[0][0]                   \n",
      "                                                                 images[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)             (None, 100352)       0           add[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "dense_11 (Dense)                (None, 512)          51380736    flatten_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_12 (Dense)                (None, 10)           5130        dense_11[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 51,682,314\n",
      "Trainable params: 51,682,314\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed to import pydot. You must install pydot and graphviz for `pydotprint` to work.\n"
     ]
    }
   ],
   "source": [
    "plot_model(model, show_shapes = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Модели как слои\n",
    "\n",
    "В слои можно заворачивать целые модели.\n",
    "\n",
    "    у = модель (х)\n",
    "\n",
    "Если модель имеет несколько входных тензоров и несколько выходных тензоров, ее следует вызывать со списком тензоров:\n",
    "\n",
    "    y1, y2 = модель ([x1, x2])\n",
    "\n",
    "Когда вы вызываете экземпляр модели, вы повторно используете вес модели - точно так же, как и при вызове экземпляра слоя. Вызов экземпляра, будь то экземпляр уровня или экземпляра модели, всегда будет повторно использовать существующие изученные представления экземпляра, что интуитивно понятно."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import applications \n",
    "\n",
    "\n",
    "nbr_classes = 10\n",
    "\n",
    "# Возьмем готовую модель Xception\n",
    "xception_base = applications.Xception(weights=None,include_top=False)\n",
    "\n",
    "# входная картинка  250 × 250 RGB.\n",
    "left_input = Input(shape=(250, 250, 3))\n",
    "right_input = Input(shape=(250, 250, 3))\n",
    "\n",
    "left_features = xception_base(left_input)\n",
    "right_features = xception_base(right_input)\n",
    "\n",
    "merged_features = layers.concatenate([left_features, right_features], axis=-1)\n",
    "\n",
    "predictions = layers.Dense(nbr_classes, activation='softmax')(merged_features)\n",
    "\n",
    "#  Собираем нашу модельку\n",
    "model = Model([left_input, right_input], predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_8\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_4 (InputLayer)            [(None, 250, 250, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_5 (InputLayer)            [(None, 250, 250, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "xception (Model)                multiple             20861480    input_4[0][0]                    \n",
      "                                                                 input_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 8, 8, 4096)   0           xception[1][0]                   \n",
      "                                                                 xception[2][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_13 (Dense)                (None, 8, 8, 10)     40970       concatenate_2[0][0]              \n",
      "==================================================================================================\n",
      "Total params: 20,902,450\n",
      "Trainable params: 20,847,922\n",
      "Non-trainable params: 54,528\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed to import pydot. You must install pydot and graphviz for `pydotprint` to work.\n"
     ]
    }
   ],
   "source": [
    "plot_model(model, show_shapes = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Итого - давайте теперь соберем модель с двумя входами, где оба входа - обработчики картинок.\n",
    "Выхода у нас тоже 2 - предположим мы решаем задачу следующего ввида - ищем как контент картинки, так и время года!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ну и на последок \n",
    " мы же все помним, мы можем писать кастомные callback. Теперь поэтапно смотрим на эту прелесть.\n",
    " \n",
    " Возьмем уже известную вам модельку с прошлой пары и будем модифицировать наши результаты."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import Sequential\n",
    "keras, L = tf.keras, tf.keras.layers\n",
    "\n",
    "import numpy as np\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "fashion_mnist = tf.keras.datasets.fashion_mnist\n",
    "\n",
    "(X_train, y_train), (X_test, y_test) = fashion_mnist.load_data()\n",
    "\n",
    "### ВАШ код предобработки данных ###\n",
    "\n",
    "\n",
    "class_names = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat',\n",
    "               'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь давайте соберём свёртоную сеть: \n",
    "\n",
    "* Свёртка с ядром $5 \\times 5$, same padding и $32$ каналами\n",
    "* ReLU\n",
    "* Макспулинг размера $2 \\times 2$\n",
    "* Свёртка с ядром $5 \\times 5$ и $16$ каналами  и same padding\n",
    "* ReLU\n",
    "* Макспулинг размера $2 \\times 2$ с шагом (strides) $2$ по обеим осям \n",
    "* Дальше сделайте `Flatten` и сделайте два полносвязных слоя с ReLU и $120$ и $60$ нейронами"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_1 = Sequential( )\n",
    "\n",
    "### и тут\n",
    "\n",
    "model_1.compile(\"adam\", \"categorical_crossentropy\", metrics=[\"categorical_accuracy\"])\n",
    "\n",
    "hist = model_1.fit(X_train, y_train, validation_split= 0.2,\n",
    "                        batch_size=500, epochs=3, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Наш класс должен быть отнаследован от керасовского класса\n",
    "\n",
    "class MyCustomCallback(tf.keras.callbacks.Callback):\n",
    "    pass\n",
    "\n",
    "# Но мы можем переписать методы, которые мы отнаследовали\n",
    "# но для начала посмотреть на них"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir(tf.keras.callbacks.Callback)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Теперь нам надо переписать методы которые нам потребуются\n",
    "# А задача в следующем - посмотреть какой класс проседает по точности на валидационных данных\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "precision_my = MyCustomCallback........"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist = model_1.fit(X_train, y_train, validation_split= 0.2,epochs=1,\n",
    "                       callbacks=[precision_my])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
