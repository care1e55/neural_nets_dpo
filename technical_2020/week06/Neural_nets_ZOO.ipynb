{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Зоопарк моделей\n",
    "\n",
    "Внутри Tensorflow лежит довольно большое число предобученных моделей. Давайте попробуем вытащить какую-нибудь модель из его анналов и к чему-нибудь применим её. \n",
    "\n",
    "Все эти модели лежат в модуле `keras.applications`. Как правило, это классификаторы изображений, которые обучале на выборке [__IMAGENET.__](http://image-net.org/)\n",
    "\n",
    "\n",
    "## 1. Я реквизирую эту VGG-16\n",
    "\n",
    "Давайте заберём себе чужую, уже обученную на ImageNet, сетку VGG-16\n",
    "\n",
    "<img align=\"center\" src=\"https://neurohive.io/wp-content/uploads/2018/11/vgg16-neural-network-1-e1542973058418.jpg\" width=\"500\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import tensorflow.keras.applications as zoo # как зоопарк подгружаем, азазазазаз"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://github.com/fchollet/deep-learning-models/releases/download/v0.1/vgg16_weights_tf_dim_ordering_tf_kernels.h5\n",
      "553467904/553467096 [==============================] - 184s 0us/step\n"
     ]
    }
   ],
   "source": [
    "model = zoo.VGG16(include_top=True, weights='imagenet')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Опция `weights` отвечает за то, на каком датасете предобучена модель. Опция `include_top` отвечает за то, скачиваем мы модель полностью или только `feature extractor`, то есть только первые слои. Мы скачали всё. \n",
    "\n",
    "Давайте посмотрим на `summary` модели и узнаем размерность входа и выхода."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"vgg16\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 224, 224, 3)]     0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 224, 224, 64)      1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 224, 224, 64)      36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 112, 112, 64)      0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 112, 112, 128)     73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 112, 112, 128)     147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 56, 56, 128)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 56, 56, 256)       295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 28, 28, 256)       0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 28, 28, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 7, 7, 512)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 25088)             0         \n",
      "_________________________________________________________________\n",
      "fc1 (Dense)                  (None, 4096)              102764544 \n",
      "_________________________________________________________________\n",
      "fc2 (Dense)                  (None, 4096)              16781312  \n",
      "_________________________________________________________________\n",
      "predictions (Dense)          (None, 1000)              4097000   \n",
      "=================================================================\n",
      "Total params: 138,357,544\n",
      "Trainable params: 138,357,544\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Можно выдернуть размерность и не смотря на `summary`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.layers[0].output_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = model.layers[0].output_shape[0][1:3]\n",
    "input_shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь попробуем что-нибудь спрогнозировать. В модуле `keras.utis` есть функция `get_file`, которая умеет скачивать и разархивировать разные файлы. Будем использовать её для скачки картинок по ссылкам. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import get_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import PIL.Image\n",
    "import numpy as np\n",
    "\n",
    "href = 'https://sadanduseless.b-cdn.net/wp-content/uploads/2019/06/cat-breading4.jpg'\n",
    "image = get_file('cat.jpg', href)\n",
    "\n",
    "print(image) # куда скачался то?! \n",
    "\n",
    "image = PIL.Image.open(image).resize(input_shape)\n",
    "image "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# немного предобработки\n",
    "image = np.array(image)/255.0\n",
    "image.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# вот так можно добавить фиктивную размерность\n",
    "image[np.newaxis, ...].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# строим прогноз \n",
    "result = model.predict(image[np.newaxis, ...])\n",
    "result.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Готово! У нас есть $1000$ вариантов прогноза. Если быть более конкретным, нас в случае данного изображения устраивает класс номер"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_class = np.argmax(result[0], axis=-1)\n",
    "predicted_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result[0].argsort()[-5:][::-1] # топ-5 классов"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Осталось только выяснить что это за класс. Для этого нам нужны метки Imagenet. Скачаем их. Они тоже уже есть в пакете. Удобно. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.python.keras.applications.vgg16 import decode_predictions\n",
    "decode_predictions(result)[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Напишем функцию для строительства прогнозов и попробуем ещё. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def save_image(href, save_name):\n",
    "    img = get_file(save_name, href)\n",
    "    return img\n",
    "    \n",
    "def predict(image_path):\n",
    "    # Подгружаем изображение и делаем его ресайз в соответсвии с моделью\n",
    "    img = PIL.Image.open(image_path)\n",
    "    \n",
    "    # тут чуть подрбнее про ресайзы: https://habr.com/ru/post/247219/\n",
    "    img_resized = img.resize(input_shape, PIL.Image.LANCZOS)\n",
    "\n",
    "    # Рисуем картинку\n",
    "    plt.imshow(img_resized)\n",
    "    plt.show()\n",
    "\n",
    "    # Кнвертируем картинку в numpy и делаем лишнюю размерность\n",
    "    img_array = np.array(img_resized)[np.newaxis, ...]\n",
    "\n",
    "    # VGG-16 строит нам прогноз\n",
    "    pred = model.predict(img_array)\n",
    "    \n",
    "    # Декодируем прогноз\n",
    "    pred_decoded = decode_predictions(pred)[0]\n",
    "\n",
    "    # Печатаем его на экран\n",
    "    for code, name, score in pred_decoded:\n",
    "        print(\"{0:>6.2%} : {1}\".format(score, name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "href = 'https://upload.wikimedia.org/wikipedia/commons/e/e7/Jack-Russell-Terrier.jpg'\n",
    "path = save_image(href, 'img_dog.jpg')\n",
    "predict(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ваши картинки "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обратите внимание, что когда мы делаем `.resize`, мы используем опцию `PIL.Image.LANCZOS` она делает кое-какие приятные ништяки, связанные с защитой изображения от искажений. Вообще борьба с искажениями и разными размерностями у картинок - один из этапов предобработки. \n",
    "\n",
    "Как добиться того, чтобы картинка не искажалась? Использовать какие-то похожие фильры, либо обрезать картинки. Давайте попробуем написать в numpy функцию, которая будет заниматься обрезанием картинок вот по такой схеме: \n",
    "\n",
    "<img src=\"https://raw.githubusercontent.com/hse-aml/intro-to-dl/master/week3/images/center_crop.jpg\" style=\"width:50%\">\n",
    "\n",
    "Попробуйте самостоятельно сделать её."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Функция для обрезания картинок \n",
    "def image_center_crop(img):\n",
    "    \n",
    "    # ваш код\n",
    "    \n",
    "    \n",
    "    return cropped_img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь найлите в интернете какую-нибудь картинку и зашвырните её в сетку без обрезания, а потом с обрезанием. Посмотрите на вероятность, с которой картинка относится к какому-то классу. Функцию `predict`, кстати говоря, придётся переписать. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "href = # картинка\n",
    "\n",
    "path = save_image(href, # имя картинки)\n",
    "predict(path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Немного перепишем функцию для прогнозирования, добавив в неё resize "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(image_path):\n",
    "    # Подгружаем изображение и делаем его ресайз в соответсвии с моделью\n",
    "    img = PIL.Image.open(image_path)\n",
    "    \n",
    "    # переделали в массив, обрезали \n",
    "    #### НАША ФУНКЦИЯ\n",
    "    img = image_center_crop(np.array(img)) \n",
    "    #################\n",
    "    \n",
    "    # вернули назад в картинку, сделали resize \n",
    "    img_resized = PIL.Image.fromarray(img).resize(input_shape)\n",
    "\n",
    "    # Рисуем картинку\n",
    "    plt.imshow(img_resized)\n",
    "    plt.show()\n",
    "\n",
    "    # Кнвертируем картинку в numpy и делаем лишнюю размерность\n",
    "    img_array = np.array(img_resized)[np.newaxis, ...]\n",
    "\n",
    "    # VGG-16 строит нам прогноз\n",
    "    pred = model.predict(img_array)\n",
    "    \n",
    "    # Декодируем прогноз\n",
    "    pred_decoded = decode_predictions(pred)[0]\n",
    "\n",
    "    # Печатаем его на экран\n",
    "    for code, name, score in pred_decoded:\n",
    "        print(\"{0:>6.2%} : {1}\".format(score, name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "href = # картинка\n",
    "\n",
    "path = save_image(href, # имя картинки\n",
    "predict(path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Другие обитатели зоопарка"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "zoo.inception_v3"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "zoo.ResNet50"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "И многие-многие другие! :) Какие-то из моделей довольно тяжёлые и много весят. Будьте осторожны при их подгрузке. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
